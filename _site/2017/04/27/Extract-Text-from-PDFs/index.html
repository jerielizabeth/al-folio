<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Jeri E. Wieringa | Extracting Text from PDFs</title>
<meta name="description" content="Work at the intersection of religious studies, history, and data science.
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/css/mdb.min.css" integrity="sha256-/SwJ2GDcEt5382i8zqDwl36VJGECxEoIcBIuoLmLR4g=" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"  integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/2017/04/27/Extract-Text-from-PDFs/">

<!-- Open Graph -->


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
      
      
      
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Jeri</span> E.  Wieringa
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Extracting Text from PDFs</h1>
    <p class="post-meta">April 27, 2017</p>
  </header>

  <article class="post-content">
    <p><em>This is <a href="http://jeriwieringa.com/portfolio/dissertation/">part of a series</a> of first drafts of the technical essays documenting the technical work that undergirds my dissertation,</em> A Gospel of Health and Salvation. <em>For an overview of the dissertation project, you can read the <a href="http://jeriwieringa.com/2017/04/21/updated-dissertation-description">current project description</a> at <a href="http://jeriwieringa.com">jeriwieringa.com</a>. You can access the Jupyter notebooks on <a href="https://github.com/jerielizabeth/Gospel-of-Health-Notebooks">Github</a>.</em></p>

<p><em>My goals in sharing the notebooks and technical essays are two-fold. First, I hope that they might prove useful to others interested in taking on similar projects. Second, I am sharing them in hopes that “<a href="https://en.wikipedia.org/wiki/Linus%27s_Law">given enough eyeballs, all bugs are shallow</a>.”</em></p>

<hr />

<p>With the PDF files downloaded, my next challenge was to extract the text. Here my choice of source base offered some advantages and some additional challenges. It is not uncommon when downloading books scanned to PDFs from providers such as Google to discover that they have only made the page images available. As many people want textual data, and preferably good textual data, for a variety of potentially lucrative computational tasks, it makes sense for companies to withhold the text layer. But for the researcher, this necessitates adding a text recognition step to the gathering process, running the pages through OCR software to generate the needed text layer. One advantage of this is that you then have control over the OCR software, but it significantly increases the time and complexity of the text gathering process.</p>

<p>The PDF files produced by the <a href="http://documents.adventistarchives.org/default.aspx">Office of Archives and Statistics</a> include the produced OCR. But unlike the newspapers scanned as part of the <a href="http://chroniclingamerica.loc.gov/">Chronicling America</a> project, there is very little information embedded in these files about the source and estimated quality of that OCR. That lack of information sets up the challenge for the next section of this module, which documents my work to assess and clean the corpus, <a href="http://jeriwieringa.com/2017/01/09/early_error_summary/">previewed in an earlier blog post</a>.</p>

<p>In extracting the text, I also had to determined my unit of analysis for text mining – the article, the page, or the issue. I quickly dismissed using the “issue” because it is too large and too irregular a unit. With issues ranging in length from 8 pages to 100 pages, and including a variety of elements from long essays to letters to the editor and field reports, I would only be able to surface summary patterns using the issue as a whole. Since I am interested in identifying shifts in discourse over time, a more fine-grained unit was necessary. For this, the “article” seemed like a very useful unit, enabling each distinct piece to be examined on its own. But the boundaries of “articles” in a newspaper type publication are actually rather hard to define, and the length of the candidate sections range from multiple-page essays to one paragraph letters or poems. In addition, the publications contain a number of article “edge cases”, such as advertisements, notices of letters received, and subscription information, which would either need to be identified and separated into their own articles or identified and excluded.</p>

<p>In the end, I chose the middle-ground solution of using the page as the document unit. While not all pages are created equal (early issues of the <em>Review and Herald</em> made great use of space and small font size to squeeze about 3000 words on a page), on average the pages contain about 1000 words, placing them in line with the units <a href="http://www.matthewjockers.net/2013/04/12/secret-recipe-for-topic-modeling-themes/">Matthew Jockers has found to be most useful when modeling novels</a>. Splitting on the page is also computationally and analytically simple, which is valuable when working at the scale of this project.</p>

<p>In addition, using the page as the unit of analysis is more reflective of the print reading experience. Rather than interacting with each article in isolation (as is modeled in many database editions of historical newspapers), the newspaper readers would experience an article within the context of the other stories on the page. This juxtaposition of items creates what Marshall McLuhan refers to as the “human interest” element of news print, constructed through the “mosaic” of the page layout.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> Using the page as the unit of analysis enables me to interact with the articles as well as the community that the collection of articles creates.</p>

<p>Having determined the unit of analysis, the technical challenge was how to split the PDF documents and extract the text. It is worth noting that not all of the methods I used to prepare my corpus are ones that I would recommend. For reasons I don’t entirely recall, but related to struggling to conceptualize how to write a function that would separate the PDFs and extract the text, I chose <a href="https://help.apple.com/automator/mac/10.12/index.html?localePath=en.lproj#/aut6e8156d85">Automator</a>, a default Mac utility, to separate the pages and extract the text from the PDF files. While this reduced the programming load, it was memory and storage intensive — through the process I managed to destroy a hard-drive by failing to realize that 100-page PDFs take up even more space when split into 100 1-page PDFs. Another downside of using Automator was that I did not have control over <a href="https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/">the encoding</a> of the generated text files. Upon attempting run the files through Python scripts, a plethora of encoding error messages quickly suggested that not all was well with my text corpus. I used the following bash script to check and report the file encodings:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">FILES</span><span class="o">=</span><span class="k">*</span>.txt
<span class="k">for </span>f <span class="k">in</span> <span class="nv">$FILES</span>
<span class="k">do
  </span><span class="nv">encoding</span><span class="o">=</span><span class="sb">`</span>file <span class="nt">-I</span> <span class="nv">$f</span> | <span class="nb">cut</span> <span class="nt">-f</span> 2 <span class="nt">-d</span><span class="s2">";"</span> | <span class="nb">cut</span> <span class="nt">-f</span> 2 <span class="nt">-d</span><span class="o">=</span><span class="sb">`</span>
  <span class="k">if</span> <span class="o">!</span> <span class="o">[</span> <span class="nv">$encoding</span> <span class="o">=</span> <span class="s2">"utf-8"</span> <span class="nt">-o</span> <span class="nv">$encoding</span> <span class="o">=</span> <span class="s2">"us-ascii"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="s2">"Check </span><span class="nv">$f</span><span class="s2">: encoding reported as </span><span class="nv">$encoding</span><span class="s2">"</span>
  <span class="k">fi 
done</span>
</code></pre></div></div>
<p>The report revealed non-utf-8 encodings from <code class="language-plaintext highlighter-rouge">latin-1</code> to <code class="language-plaintext highlighter-rouge">binary</code> on a majority of files. My attempts to use <a href="https://en.wikipedia.org/wiki/Iconv"><code class="language-plaintext highlighter-rouge">iconv</code></a> to convert the files to utf-8 raised their own collection of errors. Thanks to a suggestion from <a href="http://kimberlylapierre.weebly.com/">a very wise friend</a>, I bypassed these problems by using <code class="language-plaintext highlighter-rouge">vim</code> within a bash script to open each file and re-encode it in utf-8.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">FILES</span><span class="o">=</span><span class="k">*</span>.txt
<span class="k">for </span>f <span class="k">in</span> <span class="nv">$FILES</span>
<span class="k">do
  </span><span class="nb">echo</span> <span class="s2">"</span><span class="nv">$f</span><span class="s2">"</span>
  vim <span class="nt">-es</span> <span class="s1">'+set fileencoding=utf-8'</span> <span class="s1">'+wq'</span> <span class="nv">$f</span>
  <span class="nv">encoding</span><span class="o">=</span><span class="sb">`</span>file <span class="nt">-bi</span> <span class="nv">$f</span> | <span class="nb">cut</span> <span class="nt">-f</span> 2 <span class="nt">-d</span><span class="s2">";"</span> | <span class="nb">cut</span> <span class="nt">-f</span> 2 <span class="nt">-d</span><span class="o">=</span><span class="sb">`</span>
  <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$encoding</span><span class="s2">"</span>
<span class="k">done</span>
</code></pre></div></div>
<p>Although perhaps not an elegant solution, this process worked sufficiently to produce a directory of 197,943 text files that could be read by my Python scripts without trouble.</p>

<p>Below I outline a better way, which I use on later additions to the corpus, to extract the text from a PDF document and save each page to it’s own file using <a href="https://pythonhosted.org/PyPDF2/"><code class="language-plaintext highlighter-rouge">PyPDF2</code></a>. Using a PDF library has a number of advantages. First, it is much less resource intensive, with no intermediary documents created and, with the use of a <a href="https://docs.python.org/3/glossary.html#term-generator">generator expression</a>, no need to load the entire list of filenames into memory. Second, by placing the extraction within a more typical Python workflow, I can set the encoding when writing the extracted text to a file. This removes the complication I encountered with the Automator-generated text of relying on a program to assign the “most likely” encoding.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">isfile</span><span class="p">,</span> <span class="n">join</span>
<span class="kn">import</span> <span class="nn">PyPDF2</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""If running locally, set these variables to your local directories.
"""</span>
<span class="n">pdf_dir</span> <span class="o">=</span> <span class="s">"../../corpus/incoming"</span>
<span class="n">txt_dir</span> <span class="o">=</span> <span class="s">"../../corpus/txt_dir"</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""Note: Uses a generator expression.
Rerun the cell if you restart the loop below.
"""</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">(</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">pdf_dir</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">f</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'.'</span><span class="p">)</span> <span class="ow">and</span> <span class="n">isfile</span><span class="p">(</span><span class="n">join</span><span class="p">(</span><span class="n">pdf_dir</span><span class="p">,</span> <span class="n">f</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""The documentation for PyPDF2 is minimal. 
For this pattern, I followed the syntax at 
https://automatetheboringstuff.com/chapter13/ and
https://github.com/msaxton/iliff_review/blob/master/code/atla_pdfConvert.py
"""</span>
<span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
    <span class="c1"># Open the PDF and load as PyPDF2 Reader object.
</span>    <span class="n">pdf</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">join</span><span class="p">(</span><span class="n">pdf_dir</span><span class="p">,</span> <span class="n">filename</span><span class="p">),</span><span class="s">'rb'</span><span class="p">)</span>
    <span class="n">pdfReader</span> <span class="o">=</span> <span class="n">PyPDF2</span><span class="p">.</span><span class="n">PdfFileReader</span><span class="p">(</span><span class="n">pdf</span><span class="p">)</span>
    
    <span class="c1"># Loop through the pages, extract the text, and write each page to individual file.
</span>    <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pdfReader</span><span class="p">.</span><span class="n">numPages</span><span class="p">):</span>
        <span class="n">pageObj</span> <span class="o">=</span> <span class="n">pdfReader</span><span class="p">.</span><span class="n">getPage</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">pageObj</span><span class="p">.</span><span class="n">extractText</span><span class="p">()</span>
        
        <span class="c1"># Compile the page name. Add one because Python counts from 0.
</span>        <span class="n">page_name</span> <span class="o">=</span> <span class="s">"{}-page{}.txt"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">filename</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">],</span> <span class="n">page</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Write to each page to file
</span>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">join</span><span class="p">(</span><span class="n">txt_dir</span><span class="p">,</span> <span class="n">page_name</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s">"w"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">o</span><span class="p">:</span>
            <span class="n">o</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div></div>

<p>You can run this code locally using <a href="https://github.com/jerielizabeth/Gospel-of-Health-Notebooks/blob/d6522da8a9ce7e31cb4f08bade7f6762b13463df/module-2/corpus-creation/Extracting%20Text%20from%20PDFs.ipynb">the Jupyter Notebook</a>. Setup instructions are available in the project README.</p>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Marshall McLuhan, <em>Understanding Media: The Extensions of Man.</em> MIT Press Edition. Cambridge, MA: The MIT Press, 1994. p. 204. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2020 Jeri E. Wieringa.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.0/umd/popper.min.js" integrity="sha256-OH05DFHUWzr725HmuHo3pnuvUUn+TJuj8/Qz9xytFEw=" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/js/mdb.min.js"  integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" integrity="sha256-V8SV2MO1FUb63Bwht5Wx9x6PVHNa02gv8BgH/uH3ung=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js" integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc=" crossorigin="anonymous"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>





<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>



</html>
