<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Jeri E. Wieringa | Ways to Compute Topics over Time, Part 2</title>
<meta name="description" content="Work at the intersection of religious studies, history, and data science.
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/css/mdb.min.css" integrity="sha256-/SwJ2GDcEt5382i8zqDwl36VJGECxEoIcBIuoLmLR4g=" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"  integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/2017/06/23/calculating-and-visualizing-topic-significance-over-time-part-2/">

<!-- Open Graph -->


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
      
      
      
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Jeri</span> E.  Wieringa
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Ways to Compute Topics over Time, Part 2</h1>
    <p class="post-meta">June 23, 2017</p>
  </header>

  <article class="post-content">
    <p><em>This is <a href="http://jeriwieringa.com/portfolio/dissertation/">part of a series</a> of technical essays documenting the computational analysis that undergirds my dissertation,</em> A Gospel of Health and Salvation. <em>For an overview of the dissertation project, you can read the <a href="http://jeriwieringa.com/2017/04/21/updated-dissertation-description">current project description</a> at <a href="http://jeriwieringa.com">jeriwieringa.com</a>. You can access the Jupyter notebooks on <a href="https://github.com/jerielizabeth/Gospel-of-Health-Notebooks">Github</a>.</em></p>

<hr />

<p>This is the second in a series of posts which constitute a “lit review” of sorts, documenting the range of methods scholars are using to compute the distribution of topics over time.</p>

<p>Graphs of topic prevalence over time are some of the most ubiquitous in digital humanities discussions of topic modeling. They are used as a mechanism for identifying spikes in discourse and for depicting the relationship between the various discourses in a corpus.</p>

<p>Topic prevalence over time is not, however, a measure that is returned with the standard modeling tools such as MALLET or Gensim. Instead, it is computed after the fact by combining the model data with external metadata and aggregating the model results. And, as it turns out, there are a number of ways that the data can be aggregated and displayed.
In this series of notebooks, I am looking at 4 different strategies for computing topic significance over time. These strategies are:</p>

<ul>
  <li><a href="http://jeriwieringa.com/2017/06/21/Calculating-and-Visualizing-Topic-Significance-over-Time-Part-1/">Average of topic weights per year (First Post)</a></li>
  <li>Smoothing or regression analysis</li>
  <li>Prevalence of the top topic per year</li>
  <li>Proportion of total weights per year</li>
</ul>

<p>To explore a range of strategies for computing and visualizing topics over time from a standard LDA model, I am using a model I created from my dissertation materials. You can download the files needed to follow along from <a href="https://www.dropbox.com/s/9uf6kzkm1t12v6x/2017-06-21.zip?dl=0">https://www.dropbox.com/s/9uf6kzkm1t12v6x/2017-06-21.zip?dl=0</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load the necessary libraries
</span><span class="kn">from</span> <span class="nn">ggplot</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span> <span class="c1"># Note: I am running 0.19.2
</span><span class="kn">import</span> <span class="nn">pyLDAvis.gensim</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">warnings</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Enable in-notebook visualizations
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">pyLDAvis</span><span class="p">.</span><span class="n">enable_notebook</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Temporary fix for persistent warnings of an api change between pandas and seaborn.
</span><span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="n">options</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">10</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">base_dir</span> <span class="o">=</span> <span class="s">"data"</span>
<span class="n">period</span> <span class="o">=</span> <span class="s">"1859-to-1875"</span>
<span class="n">directory</span> <span class="o">=</span> <span class="s">"historical_periods"</span>
</code></pre></div></div>

<h1 id="create-the-dataframes">Create the dataframes</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">metadata_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span><span class="s">'2017-05-corpus-stats/2017-05-Composite-OCR-statistics.csv'</span><span class="p">)</span>
<span class="n">index_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s">'corpora'</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span> <span class="s">'{}.txt'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">period</span><span class="p">))</span>
<span class="n">labels_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s">'dataframes'</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span> <span class="s">'{}_topicLabels.csv'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">period</span><span class="p">))</span>
<span class="n">doc_topic_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s">'dataframes'</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span> <span class="s">'{}_dtm.csv'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">period</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">doc_list</span><span class="p">(</span><span class="n">index_filename</span><span class="p">):</span>
    <span class="s">"""
    Read in from a json document with index position and filename. 
    File was created during the creation of the corpus (.mm) file to document
    the filename for each file as it was processed.
    
    Returns the index information as a dataframe.
    """</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">index_filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">data_file</span><span class="p">:</span>    
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    <span class="n">docs</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s">'index'</span><span class="p">).</span><span class="n">reset_index</span><span class="p">()</span>
    <span class="n">docs</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'index_pos'</span><span class="p">,</span> <span class="s">'doc_id'</span><span class="p">]</span>
    <span class="n">docs</span><span class="p">[</span><span class="s">'index_pos'</span><span class="p">]</span> <span class="o">=</span> <span class="n">docs</span><span class="p">[</span><span class="s">'index_pos'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  
    <span class="k">return</span> <span class="n">docs</span>


<span class="k">def</span> <span class="nf">compile_dataframe</span><span class="p">(</span> <span class="n">index</span><span class="p">,</span> <span class="n">dtm</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">metadata</span><span class="p">):</span>
    <span class="s">"""
    Combines a series of dataframes to create a large composit dataframe.
    """</span>
    <span class="n">doc2metadata</span> <span class="o">=</span> <span class="n">index</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'doc_id'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">"left"</span><span class="p">)</span>
    <span class="n">topics_expanded</span> <span class="o">=</span> <span class="n">dtm</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'topic_id'</span><span class="p">)</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">topics_expanded</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">doc2metadata</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">"index_pos"</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">"left"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">metadata</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">metadata_filename</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s">'doc_id'</span><span class="p">,</span> <span class="s">'year'</span><span class="p">,</span><span class="s">'title'</span><span class="p">])</span>
<span class="n">docs_index</span> <span class="o">=</span> <span class="n">doc_list</span><span class="p">(</span><span class="n">index_filename</span><span class="p">)</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">doc_topic_filename</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">labels_filename</span><span class="p">)</span>
</code></pre></div></div>

<p>The first step, following the pattern of <a href="https://github.com/agoldst/dfrtopics/blob/43362fd4aea25caedf59f610fb02f3aaa30334ca/R/matrices.R#L373-L415">Andrew Goldstone for his topic model browser</a>, is to normalize the weights for each document, so that they total to “1”.</p>

<p>As a note, Goldstone first smooths the weights by adding the alpha hyperparameter to each of the weights, which I am not doing here.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Reorient from long to wide
</span><span class="n">dtm</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s">'index_pos'</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s">'topic_id'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="s">'topic_weight'</span><span class="p">).</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Divide each value in a row by the sum of the row to normalize the values
</span><span class="n">dtm</span> <span class="o">=</span> <span class="p">(</span><span class="n">dtm</span><span class="p">.</span><span class="n">T</span><span class="o">/</span><span class="n">dtm</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)).</span><span class="n">T</span>

<span class="c1"># Shift back to a long dataframe
</span><span class="n">dt_norm</span> <span class="o">=</span> <span class="n">dtm</span><span class="p">.</span><span class="n">stack</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">dt_norm</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'index_pos'</span><span class="p">,</span> <span class="s">'topic_id'</span><span class="p">,</span> <span class="s">'norm_topic_weight'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">compile_dataframe</span><span class="p">(</span><span class="n">docs_index</span><span class="p">,</span> <span class="n">dt_norm</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span>
</code></pre></div></div>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index_pos</th>
      <th>topic_id</th>
      <th>norm_topic_weight</th>
      <th>topic_words</th>
      <th>doc_id</th>
      <th>year</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0.045525</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page1.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page2.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page3.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page4.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page5.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>288595</th>
      <td>11539</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page4.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288596</th>
      <td>11540</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page5.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288597</th>
      <td>11541</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page6.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288598</th>
      <td>11542</td>
      <td>24</td>
      <td>0.012192</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page7.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288599</th>
      <td>11543</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page8.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
  </tbody>
</table>
<p>288600 rows × 7 columns</p>
</div>

<h1 id="data-dictionary">Data dictionary:</h1>

<ul>
  <li><code class="language-plaintext highlighter-rouge">index_pos</code> : Gensim uses the order in which the docs were streamed to link back the data and the source file. <code class="language-plaintext highlighter-rouge">index_pos</code> refers to the index id for the individual doc, which I used to link the resulting model information with the document name.</li>
  <li><code class="language-plaintext highlighter-rouge">topic_id</code> : The numerical id for each topic. For this model, I used 20 topics to classify the periodical pages.</li>
  <li><code class="language-plaintext highlighter-rouge">norm_topic_weight</code> : The proportion of the tokens in the document that are part of the topic, normalized per doc.</li>
  <li><code class="language-plaintext highlighter-rouge">topic_words</code> : The top 6 words in the topic.</li>
  <li><code class="language-plaintext highlighter-rouge">doc_id</code> : The file name of the document. The filename contains metadata information about the document, such as the periodical title, date of publication, volume, issue, and page number.</li>
  <li><code class="language-plaintext highlighter-rouge">year</code> : Year the document was published (according to the filename)</li>
  <li><code class="language-plaintext highlighter-rouge">title</code> : Periodical that the page was published in.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">order</span> <span class="o">=</span> <span class="p">[</span><span class="s">'conference, committee, report, president, secretary, resolved'</span><span class="p">,</span>
         <span class="s">'quarterly, district, society, send, sept, business'</span><span class="p">,</span>
         <span class="s">'association, publishing, chart, dollar, xxii, sign'</span><span class="p">,</span>
         <span class="s">'mother, wife, told, went, young, school'</span><span class="p">,</span>
         <span class="s">'disease, physician, tobacco, patient, poison, medicine'</span><span class="p">,</span>
         <span class="s">'wicked, immortality, righteous, adam, flesh, hell'</span><span class="p">,</span>
        <span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_plotpoint</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y_value</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrap</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">""</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"year"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_value</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'point'</span><span class="p">,</span> 
                        <span class="n">hue_order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="n">hue</span><span class="p">,</span> 
                       <span class="n">col</span><span class="o">=</span><span class="n">col</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="n">wrap</span><span class="p">,</span> <span class="n">col_order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> 
                       <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="n">aspect</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
    <span class="n">p</span><span class="p">.</span><span class="n">fig</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">p</span><span class="p">.</span><span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span>
</code></pre></div></div>

<h1 id="smoothing-or-regression-analysis">Smoothing or Regression Analysis</h1>

<p>The second popular topic visualization strategy I found is using a smoothing function to highlight trends in the data. I found this strategy was most commonly executed through the graphing library (rather than computing prior to graphing).</p>

<p>The prime example is using the <code class="language-plaintext highlighter-rouge">geom_smooth</code> option in ggplot. This is a little harder to do with Seaborn, but fortunately there is a Python port of ggplot so I can demonstrate on my model. For the sake of simplicity, and because faceting with the Python version is buggy, I will work with only one topic at a time for this experiment.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t17</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'topic_id'</span><span class="p">]</span><span class="o">==</span> <span class="mi">17</span><span class="p">]</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">loess</code> smoother is particularly designed for extrapolating trends in timeseries and noisy data, and is the default smoother in ggplot for data samples with fewer than 1000 observations. The <code class="language-plaintext highlighter-rouge">gam</code> smoother is the default for larger datasets.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> While I have more than 1000 observations, I will use both to illustrate the differences.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ggplot</span><span class="p">(</span><span class="n">t17</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'year'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'norm_topic_weight'</span><span class="p">))</span> <span class="o">+</span> <span class="n">geom_point</span><span class="p">()</span> <span class="o">+</span> <span class="n">stat_smooth</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'loess'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/img/output_22_0.png" alt="" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;ggplot: (287572516)&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ggplot</span><span class="p">(</span><span class="n">t17</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'year'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'norm_topic_weight'</span><span class="p">))</span> <span class="o">+</span> <span class="n">geom_point</span><span class="p">()</span> <span class="o">+</span> <span class="n">stat_smooth</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'gam'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/img/output_23_0.png" alt="" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;ggplot: (-9223372036567940983)&gt;
</code></pre></div></div>

<p>The collection of “0” values appears to have caused the function to flatline at “0” so let’s filter those out (cringing as we do, because now the total number of observations each year will vary). If you are using data produced by MALLET you might not have this problem. But someone else can experiment with that.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Drop all rows where the topic weight is 0
</span><span class="n">t17f</span> <span class="o">=</span> <span class="n">t17</span><span class="p">[</span><span class="n">t17</span><span class="p">[</span><span class="s">'norm_topic_weight'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ggplot</span><span class="p">(</span><span class="n">t17f</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'year'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'norm_topic_weight'</span><span class="p">))</span> <span class="o">+</span> <span class="n">geom_point</span><span class="p">()</span> <span class="o">+</span> <span class="n">stat_smooth</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'loess'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/img/output_26_0.png" alt="" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;ggplot: (287168092)&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ggplot</span><span class="p">(</span><span class="n">t17f</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'year'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'norm_topic_weight'</span><span class="p">))</span> <span class="o">+</span> <span class="n">geom_point</span><span class="p">()</span> <span class="o">+</span> <span class="n">stat_smooth</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'gam'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/img/output_27_0.png" alt="" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;ggplot: (287167152)&gt;
</code></pre></div></div>

<p>While not quite as pretty as the graphs from R, these graphs help illustrate the calculations.</p>

<p>The first observation is that the lines are functionally equivalent, so both smoothing functions found a similar line.</p>

<p>Looking at the line, we see a gradual increase over the first 7 years of the dataset, a more rapid increase between 1866 and 1869, and then leveling off at around 25% for the rest of the period. That matches what we saw when charting averages in the last post, though it hides the variations from year to year.</p>

<p>Topic 17, or “disease, physician, tobacco, patient, poison, medicine” was a topic with a large shift in our corpus, so for comparison, let us look at a more typical topic.</p>

<p>Topic 20: “mother, wife, told, went, young, school”</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t20</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'topic_id'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">20</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ggplot</span><span class="p">(</span><span class="n">t20</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'year'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'norm_topic_weight'</span><span class="p">))</span> <span class="o">+</span> <span class="n">geom_point</span><span class="p">()</span> <span class="o">+</span> <span class="n">stat_smooth</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'loess'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/img/output_31_0.png" alt="" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;ggplot: (-9223372036567088787)&gt;
</code></pre></div></div>

<p>My best guess as to why the unfiltered topic 20 does not flatline at “0” where topic 17 did is that while health topics are either present or not on a page (and so have a high proportion of “0” value documents), “mother, wife, told, went, young, school” is a recurring feature of most pages in a given year.</p>

<p>This could indicate that we need more topics in our model. But it also suggests something interesting about the language of the denomination that this topic is consistently part of the conversation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t20f</span> <span class="o">=</span> <span class="n">t20</span><span class="p">[</span><span class="n">t20</span><span class="p">[</span><span class="s">'norm_topic_weight'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ggplot</span><span class="p">(</span><span class="n">t20f</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'year'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'norm_topic_weight'</span><span class="p">))</span> <span class="o">+</span> <span class="n">geom_point</span><span class="p">()</span> <span class="o">+</span> <span class="n">stat_smooth</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'loess'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/img/output_34_0.png" alt="" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;ggplot: (288187824)&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ggplot</span><span class="p">(</span><span class="n">t20f</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'year'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'norm_topic_weight'</span><span class="p">))</span> <span class="o">+</span> <span class="n">geom_point</span><span class="p">()</span> <span class="o">+</span> <span class="n">stat_smooth</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'gam'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/img/output_35_0.png" alt="" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;ggplot: (-9223372036566588149)&gt;
</code></pre></div></div>

<p>While removing the “0” values did result in moving the line up ever so slightly, the overall pattern is the same.</p>

<h2 id="rolling-averages">Rolling Averages</h2>

<p>While smoothing uses linear regression to identify trend lines, another strategy for computing the overall trajectory of a topic is to visualize the average on a rolling time window (such as computing the 5 year average.) This approach  emphasizes longer term patterns in topic weight. An example of this can be seen in the work of John Laudun and Jonathan Goodwin in “<a href="muse.jhu.edu/article/524280">Computing Folklore Studies: Mapping over a Century of Scholarly Production through Topics</a>.”<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup></p>

<p>Computing average over time is one calculation I struggled to work with. Back in Part 1, I mentioned that one of the big differences between the output from MALLET and Gensim is while Mallet returns a weight for every topic in every document, Gensim filters out the weights under 1%. Depending on how you handle the data, that can drastically effect the way averages are computed. If you have a weight for all topics in documents, then the average is over the whole corpus. If you only have weights for the significant topic assignments, things get wonky really fast.</p>

<p>Since we “inflated” our dataframe to include a “0” topic weight for all missing values in the Gensim output, the denominator for all of our averages is the same. That being the case, I believe we can compute the rolling mean by taking the average each year and then using the <code class="language-plaintext highlighter-rouge">rolling_mean</code> function in Pandas to compute the average across them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Group the data by year and compute the mean of the topic weights
</span><span class="n">t17grouped</span> <span class="o">=</span> <span class="n">t17</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'year'</span><span class="p">)[</span><span class="s">'norm_topic_weight'</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Compute the rolling mean per year and rename the columns for graphing.
</span><span class="n">t17rolling</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">rolling_mean</span><span class="p">(</span><span class="n">t17grouped</span><span class="p">,</span> <span class="mi">3</span><span class="p">).</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">t17rolling</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'year'</span><span class="p">,</span> <span class="s">'rolling_mean'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_plotpoint</span><span class="p">(</span><span class="n">t17rolling</span><span class="p">,</span> <span class="s">'rolling_mean'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.FacetGrid at 0x112577c18&gt;
</code></pre></div></div>

<p><img src="/assets/img/output_41_1.png" alt="" /></p>

<p>One thing to keep in mind is that both the linear smoothing and the rolling mean are strategies developed particularly for timeseries data, or data that is produced on regular intervals by some recording instrument. While an individual journal might be released on a semi-regular schedule, once we are working across multiple publications, this gets much more complicated. Because I don’t have “real” timeseries data, I am hesitant about this approach.</p>

<p>Both the smoothing function in <code class="language-plaintext highlighter-rouge">ggplot</code> and the use of a rolling mean are methods for capturing the overall trend of a topic over time. In some ways, this feels like the holy grail metric — we are computing the trajectory of a particular discourse. But it is also an even more abstracted depiction of the topic weights than we drew when computing the averages. In describing his choice of bars to represent topic prevalence in a given year, Goldstone notes “I have chosen bars to emphasize that the model does not assume a smooth evolution in topics, and neither should we; this does make it harder to see a time trend, however.”<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup></p>

<p>Both the smoothing function and the rolling mean are strategies for minimizing the dips and spikes of a particular year. If your question relates to the long-term trend of a topic (assuming your document base can support it), that is its advantage. But if your question is about discourse at a particular point or smaller period of time, then that is the weakness.</p>

<p>Next up: topic prevalence, in an epidemiology sort of way.</p>

<p><em>You can download and run the code locally using the <a href="https://github.com/jerielizabeth/Gospel-of-Health-Notebooks/blob/master/blogPosts/Calculating%20and%20Visualizing%20Topic%20Significance%20over%20Time%2C%20Part%202.ipynb">Jupyter Notebook version of this post</a></em></p>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>http://ggplot2.tidyverse.org/reference/geom_smooth.html <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>John Laudun and Jonathan Goodwin. “Computing Folklore Studies: Mapping over a Century of Scholarly Production through Topics.” Journal of American Folklore 126, no. 502 (2013): 455-475. <a href="https://muse.jhu.edu/">https://muse.jhu.edu/</a> (accessed June 23, 2017). <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>https://agoldst.github.io/dfr-browser/ <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2020 Jeri E. Wieringa.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.0/umd/popper.min.js" integrity="sha256-OH05DFHUWzr725HmuHo3pnuvUUn+TJuj8/Qz9xytFEw=" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/js/mdb.min.js"  integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" integrity="sha256-V8SV2MO1FUb63Bwht5Wx9x6PVHNa02gv8BgH/uH3ung=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js" integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc=" crossorigin="anonymous"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>





<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>



</html>
