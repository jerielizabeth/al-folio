<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Jeri E. Wieringa | Ways to Compute Topics over Time, Part 3</title>
<meta name="description" content="Work at the intersection of religious studies, history, and data science.
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/css/mdb.min.css" integrity="sha256-/SwJ2GDcEt5382i8zqDwl36VJGECxEoIcBIuoLmLR4g=" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"  integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/2017/06/30/calculating-and-visualizing-topic-significance-over-time-part-3/">

<!-- Open Graph -->


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
      
      
      
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Jeri</span> E.  Wieringa
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Ways to Compute Topics over Time, Part 3</h1>
    <p class="post-meta">June 30, 2017</p>
  </header>

  <article class="post-content">
    <p><em>This is <a href="http://jeriwieringa.com/portfolio/dissertation/">part of a series</a> of technical essays documenting the computational analysis that undergirds my dissertation,</em> A Gospel of Health and Salvation. <em>For an overview of the dissertation project, you can read the <a href="http://jeriwieringa.com/2017/04/21/updated-dissertation-description">current project description</a> at <a href="http://jeriwieringa.com">jeriwieringa.com</a>. You can access the Jupyter notebooks on <a href="https://github.com/jerielizabeth/Gospel-of-Health-Notebooks">Github</a>.</em></p>

<hr />

<p>This is the third in a series of posts which constitute a “lit review” of sorts, documenting the range of methods scholars are using to compute the distribution of topics over time.</p>

<p>Graphs of topic prevalence over time are some of the most ubiquitous in digital humanities discussions of topic modeling. They are used as a mechanism for identifying spikes in discourse and for depicting the relationship between the various discourses in a corpus.</p>

<p>Topic prevalence over time is not, however, a measure that is returned with the standard modeling tools such as MALLET or Gensim. Instead, it is computed after the fact by combining the model data with external metadata and aggregating the model results. And, as it turns out, there are a number of ways that the data can be aggregated and displayed.
In this series of notebooks, I am looking at 4 different strategies for computing topic significance over time. These strategies are:</p>

<ul>
  <li><a href="http://jeriwieringa.com/2017/06/21/Calculating-and-Visualizing-Topic-Significance-over-Time-Part-1/">Average of topic weights per year (First Post)</a></li>
  <li><a href="http://jeriwieringa.com/2017/06/23/calculating-and-visualizing-topic-significance-over-time-part-2/">Smoothing or regression analysis (Second Post)</a></li>
  <li><a href="http://jeriwieringa.com/2017/06/30/calculating-and-visualizing-topic-significance-over-time-part-3/">Prevalence of the top topic per year (Third Post)</a></li>
  <li>Proportion of total weights per year</li>
</ul>

<p>To explore a range of strategies for computing and visualizing topics over time from a standard LDA model, I am using a model I created from my dissertation materials. You can download the files needed to follow along from <a href="https://www.dropbox.com/s/9uf6kzkm1t12v6x/2017-06-21.zip?dl=0"> https://www.dropbox.com/s/9uf6kzkm1t12v6x/2017-06-21.zip?dl=0</a>.</p>

<p>If you cloned the notebooks from one of the earlier posts, please pull down the latest version and update your environment (see the <a href="https://github.com/jerielizabeth/Gospel-of-Health-Notebooks/blob/master/README.md">README</a> for help). I forgot to add a few libraries that are needed to run these notebooks.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load the necessary libraries
</span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span> <span class="c1"># Note: I am running 0.19.2
</span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Enable in-notebook visualizations
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="n">options</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">10</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">base_dir</span> <span class="o">=</span> <span class="s">"data"</span>
<span class="n">period</span> <span class="o">=</span> <span class="s">'1859-to-1875'</span>
<span class="n">directory</span> <span class="o">=</span> <span class="s">"historical_periods"</span>
</code></pre></div></div>

<h1 id="create-the-dataframes">Create the dataframes</h1>

<p>I preprocessed the model to export various aspects of the model information into CSV files for ease of compiling. I will be releasing the code I used to export that information in a later notebook.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">metadata_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span><span class="s">'2017-05-corpus-stats/2017-05-Composite-OCR-statistics.csv'</span><span class="p">)</span>
<span class="n">index_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s">'corpora'</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span> <span class="s">'{}.txt'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">period</span><span class="p">))</span>
<span class="n">labels_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s">'dataframes'</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span> <span class="s">'{}_topicLabels.csv'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">period</span><span class="p">))</span>
<span class="n">doc_topic_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s">'dataframes'</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span> <span class="s">'{}_dtm.csv'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">period</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">doc_list</span><span class="p">(</span><span class="n">index_filename</span><span class="p">):</span>
    <span class="s">"""
    Read in from a json document with index position and filename. 
    File was created during the creation of the corpus (.mm) file to document
    the filename for each file as it was processed.
    
    Returns the index information as a dataframe.
    """</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">index_filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">data_file</span><span class="p">:</span>    
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    <span class="n">docs</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s">'index'</span><span class="p">).</span><span class="n">reset_index</span><span class="p">()</span>
    <span class="n">docs</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'index_pos'</span><span class="p">,</span> <span class="s">'doc_id'</span><span class="p">]</span>
    <span class="n">docs</span><span class="p">[</span><span class="s">'index_pos'</span><span class="p">]</span> <span class="o">=</span> <span class="n">docs</span><span class="p">[</span><span class="s">'index_pos'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  
    <span class="k">return</span> <span class="n">docs</span>


<span class="k">def</span> <span class="nf">compile_dataframe</span><span class="p">(</span> <span class="n">index</span><span class="p">,</span> <span class="n">dtm</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">metadata</span><span class="p">):</span>
    <span class="s">"""
    Combines a series of dataframes to create a large composit dataframe.
    """</span>
    <span class="n">doc2metadata</span> <span class="o">=</span> <span class="n">index</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'doc_id'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">"left"</span><span class="p">)</span>
    <span class="n">topics_expanded</span> <span class="o">=</span> <span class="n">dtm</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'topic_id'</span><span class="p">)</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">topics_expanded</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">doc2metadata</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">"index_pos"</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">"left"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">order</span> <span class="o">=</span> <span class="p">[</span><span class="s">'conference, committee, report, president, secretary, resolved'</span><span class="p">,</span>
         <span class="s">'quarterly, district, society, send, sept, business'</span><span class="p">,</span>
         <span class="s">'association, publishing, chart, dollar, xxii, sign'</span><span class="p">,</span>
         <span class="s">'mother, wife, told, went, young, school'</span><span class="p">,</span>
         <span class="s">'disease, physician, tobacco, patient, poison, medicine'</span><span class="p">,</span>
         <span class="s">'wicked, immortality, righteous, adam, flesh, hell'</span><span class="p">,</span>
        <span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_plotpoint</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y_value</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrap</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">""</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"year"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_value</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'point'</span><span class="p">,</span> <span class="n">hue_order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="n">hue</span><span class="p">,</span> 
                       <span class="n">col</span><span class="o">=</span><span class="n">col</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="n">wrap</span><span class="p">,</span> <span class="n">col_order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="n">aspect</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
    <span class="n">p</span><span class="p">.</span><span class="n">fig</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">p</span><span class="p">.</span><span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">metadata</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">metadata_filename</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s">'doc_id'</span><span class="p">,</span> <span class="s">'year'</span><span class="p">,</span><span class="s">'title'</span><span class="p">])</span>
<span class="n">docs_index</span> <span class="o">=</span> <span class="n">doc_list</span><span class="p">(</span><span class="n">index_filename</span><span class="p">)</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">doc_topic_filename</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">labels_filename</span><span class="p">)</span>
</code></pre></div></div>

<p>The first step, following the pattern of <a href="https://github.com/agoldst/dfrtopics/blob/43362fd4aea25caedf59f610fb02f3aaa30334ca/R/matrices.R#L373-L415">Andrew Goldstone for his topic model browser</a>, is to normalize the weights for each document, so that they total to “1”.</p>

<p>As a note, Goldstone first smooths the weights by adding the alpha hyperparameter to each of the weights, which I am not doing here.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Reorient from long to wide
</span><span class="n">dtm</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s">'index_pos'</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s">'topic_id'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="s">'topic_weight'</span><span class="p">).</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Divide each value in a row by the sum of the row to normalize the values
# Since last week I have found a cleaner way to normalize the rows.
# https://stackoverflow.com/questions/18594469/normalizing-a-pandas-dataframe-by-row
</span><span class="n">dtm</span> <span class="o">=</span> <span class="n">dtm</span><span class="p">.</span><span class="n">div</span><span class="p">(</span><span class="n">dtm</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Shift back to a long dataframe
</span><span class="n">dt_norm</span> <span class="o">=</span> <span class="n">dtm</span><span class="p">.</span><span class="n">stack</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">dt_norm</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'index_pos'</span><span class="p">,</span> <span class="s">'topic_id'</span><span class="p">,</span> <span class="s">'norm_topic_weight'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">compile_dataframe</span><span class="p">(</span><span class="n">docs_index</span><span class="p">,</span> <span class="n">dt_norm</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span>
</code></pre></div></div>

<div>
<style>
    .dataframe {
        font-size: 12px;
    }
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index_pos</th>
      <th>topic_id</th>
      <th>norm_topic_weight</th>
      <th>topic_words</th>
      <th>doc_id</th>
      <th>year</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0.045525</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page1.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page2.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page3.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page4.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page5.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>288595</th>
      <td>11539</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page4.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288596</th>
      <td>11540</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page5.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288597</th>
      <td>11541</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page6.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288598</th>
      <td>11542</td>
      <td>24</td>
      <td>0.012192</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page7.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288599</th>
      <td>11543</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page8.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
  </tbody>
</table>
<p>288600 rows × 7 columns</p>
</div>

<h1 id="data-dictionary">Data dictionary:</h1>

<ul>
  <li><code class="language-plaintext highlighter-rouge">index_pos</code> : Gensim uses the order in which the docs were streamed to link back the data and the source file. <code class="language-plaintext highlighter-rouge">index_pos</code> refers to the index id for the individual doc, which I used to link the resulting model information with the document name.</li>
  <li><code class="language-plaintext highlighter-rouge">topic_id</code> : The numerical id for each topic. For this model, I used 20 topics to classify the periodical pages.</li>
  <li><code class="language-plaintext highlighter-rouge">norm_topic_weight</code> : The proportion of the tokens in the document that are part of the topic, normalized per doc.</li>
  <li><code class="language-plaintext highlighter-rouge">topic_words</code> : The top 6 words in the topic.</li>
  <li><code class="language-plaintext highlighter-rouge">doc_id</code> : The file name of the document. The filename contains metadata information about the document, such as the periodical title, date of publication, volume, issue, and page number.</li>
  <li><code class="language-plaintext highlighter-rouge">year</code> : Year the document was published (according to the filename)</li>
  <li><code class="language-plaintext highlighter-rouge">title</code> : Periodical that the page was published in.</li>
</ul>

<h1 id="computing-topic-prevalence">Computing Topic Prevalence</h1>

<p>The third approach I found for calculating topic significance over time is computing the topic prevalence. The primary example I found of this approach is Adrien Guille’s TOM, <a href="http://mediamining.univ-lyon2.fr/people/guille/tom.php#about">TOpic Modeling</a>, library for Python. Rather than averaging the weights, his approach is to set a baseline for determining whether a topic is significantly present (in this case, it is the topic with the highest weight for a document) and then computing the percentage of documents in a given year where the topic is significantly present.</p>

<p>Following the <a href="https://github.com/AdrienGuille/TOM/blob/master/tom_lib/nlp/topic_model.py#L167-L183">pattern in the TOM library</a>, we can compute the prevalence of the topics by identifying the topic with the highest weight per document, grouping the results by year, adding up the number of top occurrences of each topic per year and dividing by the total number of documents per year.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Group by document and take the row with max topic weight for each document
</span><span class="n">max_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'index_pos'</span><span class="p">])[</span><span class="s">'norm_topic_weight'</span><span class="p">].</span><span class="n">transform</span><span class="p">(</span><span class="nb">max</span><span class="p">)</span> <span class="o">==</span> <span class="n">df</span><span class="p">[</span><span class="s">'norm_topic_weight'</span><span class="p">]]</span>

<span class="c1"># Group by year and topic, counting the number of documents per topic per year.
</span><span class="n">max_counts</span> <span class="o">=</span> <span class="n">max_df</span><span class="p">[[</span><span class="s">'doc_id'</span><span class="p">,</span> <span class="s">'year'</span><span class="p">,</span> <span class="s">'topic_id'</span><span class="p">]].</span><span class="n">groupby</span><span class="p">([</span><span class="s">'year'</span><span class="p">,</span> <span class="s">'topic_id'</span><span class="p">]).</span><span class="n">agg</span><span class="p">({</span><span class="s">'doc_id'</span> <span class="p">:</span> <span class="s">'count'</span><span class="p">}).</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">max_counts</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'year'</span><span class="p">,</span> <span class="s">'topic_id'</span><span class="p">,</span> <span class="s">'max_count'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Count the number of individual documents per year
</span><span class="n">total_docs</span> <span class="o">=</span> <span class="n">max_df</span><span class="p">[[</span><span class="s">'year'</span><span class="p">,</span> <span class="s">'doc_id'</span><span class="p">]].</span><span class="n">groupby</span><span class="p">(</span><span class="s">'year'</span><span class="p">).</span><span class="n">agg</span><span class="p">({</span><span class="s">'doc_id'</span> <span class="p">:</span> <span class="s">'count'</span><span class="p">}).</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">total_docs</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'year'</span><span class="p">,</span> <span class="s">'total_docs'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Combine the two dataframes
</span><span class="n">max_counts</span> <span class="o">=</span> <span class="n">max_counts</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">total_docs</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'year'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">'left'</span><span class="p">)</span>

<span class="c1"># Create a new column with the count per topic divided by the total docs per year
</span><span class="n">max_counts</span><span class="p">[</span><span class="s">'prevalence'</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_counts</span><span class="p">[</span><span class="s">'max_count'</span><span class="p">]</span><span class="o">/</span><span class="n">max_counts</span><span class="p">[</span><span class="s">'total_docs'</span><span class="p">]</span>

<span class="c1"># Add the topic labels to make human-readable
</span><span class="n">max_counts</span> <span class="o">=</span> <span class="n">max_counts</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">"topic_id"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">max_counts</span>
</code></pre></div></div>

<div>
<style>
    .dataframe {
        font-size: 12px;
    }
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>topic_id</th>
      <th>max_count</th>
      <th>total_docs</th>
      <th>prevalence</th>
      <th>topic_words</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1859</td>
      <td>0</td>
      <td>90</td>
      <td>512</td>
      <td>0.175781</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1860</td>
      <td>0</td>
      <td>79</td>
      <td>512</td>
      <td>0.154297</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1861</td>
      <td>0</td>
      <td>79</td>
      <td>408</td>
      <td>0.193627</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1862</td>
      <td>0</td>
      <td>67</td>
      <td>514</td>
      <td>0.130350</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1863</td>
      <td>0</td>
      <td>59</td>
      <td>424</td>
      <td>0.139151</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>352</th>
      <td>1867</td>
      <td>2</td>
      <td>1</td>
      <td>951</td>
      <td>0.001052</td>
      <td>animal, fruit, horse, flesh, sheep, gardner</td>
    </tr>
    <tr>
      <th>353</th>
      <td>1872</td>
      <td>2</td>
      <td>7</td>
      <td>904</td>
      <td>0.007743</td>
      <td>animal, fruit, horse, flesh, sheep, gardner</td>
    </tr>
    <tr>
      <th>354</th>
      <td>1874</td>
      <td>2</td>
      <td>3</td>
      <td>883</td>
      <td>0.003398</td>
      <td>animal, fruit, horse, flesh, sheep, gardner</td>
    </tr>
    <tr>
      <th>355</th>
      <td>1869</td>
      <td>16</td>
      <td>3</td>
      <td>682</td>
      <td>0.004399</td>
      <td>association, publishing, chart, dollar, xxii, ...</td>
    </tr>
    <tr>
      <th>356</th>
      <td>1872</td>
      <td>16</td>
      <td>1</td>
      <td>904</td>
      <td>0.001106</td>
      <td>association, publishing, chart, dollar, xxii, ...</td>
    </tr>
  </tbody>
</table>
<p>357 rows × 6 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Limit to our 5 test topics
</span><span class="n">mc_s</span> <span class="o">=</span> <span class="n">max_counts</span><span class="p">[(</span><span class="n">max_counts</span><span class="p">[</span><span class="s">'topic_id'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">15</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">max_counts</span><span class="p">[</span><span class="s">'topic_id'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">20</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_plotpoint</span><span class="p">(</span><span class="n">mc_s</span><span class="p">,</span> <span class="s">'prevalence'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'topic_words'</span><span class="p">,</span>
                 <span class="n">title</span><span class="o">=</span><span class="s">'Percentage of documents where topic is most significant per year'</span>
                <span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.FacetGrid at 0x114eebf98&gt;
</code></pre></div></div>

<p><img src="/assets/img/output_24_1.png" alt="" /></p>

<p>If we look back at our chart of the average topic weights per year, we can see that the two sets of lines are similar, but not the same. If we rely on prevalence, we see a larger spike of interest in health in 1867, in terms of pages dedicated to the topic. We also see more dramatic spikes in our topic on “mother, wife, told, went, young, school.”</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_plotpoint</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s">'norm_topic_weight'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'topic_words'</span><span class="p">,</span>
                 <span class="n">title</span><span class="o">=</span><span class="s">'Central range of topic weights by year.'</span>
                <span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.FacetGrid at 0x1154bc400&gt;
</code></pre></div></div>

<p><img src="/assets/img/output_26_1.png" alt="" /></p>

<p>While not apparent from the data discussed here, the spikes in “mother, wife, told, went, young, school” correspond with the years where <em>The Youth’s Instructor</em> is part of the corpus (1859, 1860, 1862, 1870, 1871, 1872). While the topic is clearly capturing language that occurs in multiple publications, the presence or absence of the title has a noticeable effect. We can use smoothing to adjust for the missing data (if we’re interested in the overall trajectory of the topic), or use the information to frame our exploration what the topic is capturing.</p>

<hr />

<p><em>You can download and run the code locally using the <a href="https://github.com/jerielizabeth/Gospel-of-Health-Notebooks/blob/master/blogPosts/Calculating%20and%20Visualizing%20Topic%20Significance%20over%20Time%2C%20Part%203.ipynb">Jupyter Notebook version of this post</a></em></p>


  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2020 Jeri E. Wieringa.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.0/umd/popper.min.js" integrity="sha256-OH05DFHUWzr725HmuHo3pnuvUUn+TJuj8/Qz9xytFEw=" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/js/mdb.min.js"  integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" integrity="sha256-V8SV2MO1FUb63Bwht5Wx9x6PVHNa02gv8BgH/uH3ung=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js" integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc=" crossorigin="anonymous"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>





<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>



</html>
