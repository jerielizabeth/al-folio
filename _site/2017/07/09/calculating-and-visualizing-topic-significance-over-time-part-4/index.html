<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Jeri E. Wieringa | Ways to Compute Topics over Time, Part 4</title>
<meta name="description" content="Work at the intersection of religious studies, history, and data science.
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/css/mdb.min.css" integrity="sha256-/SwJ2GDcEt5382i8zqDwl36VJGECxEoIcBIuoLmLR4g=" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"  integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/2017/07/09/calculating-and-visualizing-topic-significance-over-time-part-4/">

<!-- Open Graph -->


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
      
      
      
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Jeri</span> E.  Wieringa
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Ways to Compute Topics over Time, Part 4</h1>
    <p class="post-meta">July 9, 2017</p>
  </header>

  <article class="post-content">
    <p><em>This is <a href="http://jeriwieringa.com/portfolio/dissertation/">part of a series</a> of technical essays documenting the computational analysis that undergirds my dissertation,</em> A Gospel of Health and Salvation. <em>For an overview of the dissertation project, you can read the <a href="http://jeriwieringa.com/2017/04/21/updated-dissertation-description">current project description</a> at <a href="http://jeriwieringa.com">jeriwieringa.com</a>. You can access the Jupyter notebooks on <a href="https://github.com/jerielizabeth/Gospel-of-Health-Notebooks">Github</a>.</em></p>

<hr />

<p>This is the last in a series of posts which constitute a “lit review” of sorts, documenting the range of methods scholars are using to compute the distribution of topics over time. The strategies I am considering are:</p>

<ul>
  <li><a href="http://jeriwieringa.com/2017/06/21/Calculating-and-Visualizing-Topic-Significance-over-Time-Part-1/">Average of topic weights per year (First Post)</a></li>
  <li><a href="http://jeriwieringa.com/2017/06/23/calculating-and-visualizing-topic-significance-over-time-part-2/">Smoothing or regression analysis (Second Post)</a></li>
  <li><a href="http://jeriwieringa.com/2017/06/30/calculating-and-visualizing-topic-significance-over-time-part-3/">Prevalence of the top topic per year (Third Post)</a></li>
  <li><a href="http://jeriwieringa.com/2017/07/09/calculating-and-visualizing-topic-significance-over-time-part-4/">Proportion of total weights per year (Final Post)</a></li>
</ul>

<p>To explore a range of strategies for computing and visualizing topics over time from a standard LDA model, I am using a model I created from my dissertation materials. You can download the files needed to follow along from <a href="https://www.dropbox.com/s/9uf6kzkm1t12v6x/2017-06-21.zip?dl=0">https://www.dropbox.com/s/9uf6kzkm1t12v6x/2017-06-21.zip?dl=0</a>.</p>

<!--more-->

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load the necessary libraries
</span><span class="kn">import</span> <span class="nn">gensim</span> <span class="c1"># Note: I am running 1.0.1
</span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span> <span class="c1"># Note: I am running 0.19.2
</span><span class="kn">import</span> <span class="nn">pyLDAvis.gensim</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">warnings</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Enable in-notebook visualizations
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Temporary fix for persistent warnings of an api change between pandas and seaborn.
</span><span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="n">options</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">10</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">base_dir</span> <span class="o">=</span> <span class="s">"data"</span>
<span class="n">period</span> <span class="o">=</span> <span class="s">"1859-to-1875"</span>
<span class="n">directory</span> <span class="o">=</span> <span class="s">"historical_periods"</span>
</code></pre></div></div>

<h1 id="create-the-dataframes">Create the dataframes</h1>

<p>I preprocessed the model to export various aspects of the model information into CSV files for ease of compiling.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">metadata_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span><span class="s">'2017-05-corpus-stats/2017-05-Composite-OCR-statistics.csv'</span><span class="p">)</span>
<span class="n">index_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s">'corpora'</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span> <span class="s">'{}.txt'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">period</span><span class="p">))</span>
<span class="n">labels_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s">'dataframes'</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span> <span class="s">'{}_topicLabels.csv'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">period</span><span class="p">))</span>
<span class="n">doc_topic_filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s">'dataframes'</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span> <span class="s">'{}_dtm.csv'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">period</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">doc_list</span><span class="p">(</span><span class="n">index_filename</span><span class="p">):</span>
    <span class="s">"""
    Read in from a json document with index position and filename. 
    File was created during the creation of the corpus (.mm) file to document
    the filename for each file as it was processed.
    
    Returns the index information as a dataframe.
    """</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">index_filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">data_file</span><span class="p">:</span>    
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    <span class="n">docs</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s">'index'</span><span class="p">).</span><span class="n">reset_index</span><span class="p">()</span>
    <span class="n">docs</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'index_pos'</span><span class="p">,</span> <span class="s">'doc_id'</span><span class="p">]</span>
    <span class="n">docs</span><span class="p">[</span><span class="s">'index_pos'</span><span class="p">]</span> <span class="o">=</span> <span class="n">docs</span><span class="p">[</span><span class="s">'index_pos'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  
    <span class="k">return</span> <span class="n">docs</span>


<span class="k">def</span> <span class="nf">compile_dataframe</span><span class="p">(</span> <span class="n">index</span><span class="p">,</span> <span class="n">dtm</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">metadata</span><span class="p">):</span>
    <span class="s">"""
    Combines a series of dataframes to create a large composit dataframe.
    """</span>
    <span class="n">doc2metadata</span> <span class="o">=</span> <span class="n">index</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'doc_id'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">"left"</span><span class="p">)</span>
    <span class="n">topics_expanded</span> <span class="o">=</span> <span class="n">dtm</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'topic_id'</span><span class="p">)</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">topics_expanded</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">doc2metadata</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">"index_pos"</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">"left"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">order</span> <span class="o">=</span> <span class="p">[</span><span class="s">'conference, committee, report, president, secretary, resolved'</span><span class="p">,</span>
         <span class="s">'quarterly, district, society, send, sept, business'</span><span class="p">,</span>
         <span class="s">'association, publishing, chart, dollar, xxii, sign'</span><span class="p">,</span>
         <span class="s">'mother, wife, told, went, young, school'</span><span class="p">,</span>
         <span class="s">'disease, physician, tobacco, patient, poison, medicine'</span><span class="p">,</span>
         <span class="s">'wicked, immortality, righteous, adam, flesh, hell'</span><span class="p">,</span>
        <span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_pointplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y_value</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrap</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">""</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"year"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_value</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'point'</span><span class="p">,</span> <span class="n">hue_order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="n">hue</span><span class="p">,</span> 
                       <span class="n">col</span><span class="o">=</span><span class="n">col</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="n">wrap</span><span class="p">,</span> <span class="n">col_order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="n">aspect</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
    <span class="n">p</span><span class="p">.</span><span class="n">fig</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">p</span><span class="p">.</span><span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">metadata</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">metadata_filename</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s">'doc_id'</span><span class="p">,</span> <span class="s">'year'</span><span class="p">,</span><span class="s">'title'</span><span class="p">])</span>
<span class="n">docs_index</span> <span class="o">=</span> <span class="n">doc_list</span><span class="p">(</span><span class="n">index_filename</span><span class="p">)</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">doc_topic_filename</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">labels_filename</span><span class="p">)</span>
</code></pre></div></div>

<p>The first step, following the pattern of <a href="https://github.com/agoldst/dfrtopics/blob/43362fd4aea25caedf59f610fb02f3aaa30334ca/R/matrices.R#L373-L415">Andrew Goldstone for his topic model browser</a>, is to normalize the weights for each document, so that they total to “1”.</p>

<p>As a note, Goldstone first smooths the weights by adding the alpha hyperparameter to each of the weights, which I am not doing here.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Reorient from long to wide
</span><span class="n">dtm</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s">'index_pos'</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s">'topic_id'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="s">'topic_weight'</span><span class="p">).</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Divide each value in a row by the sum of the row to normalize the values
# https://stackoverflow.com/questions/18594469/normalizing-a-pandas-dataframe-by-row
</span><span class="n">dtm</span> <span class="o">=</span> <span class="n">dtm</span><span class="p">.</span><span class="n">div</span><span class="p">(</span><span class="n">dtm</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Shift back to a long dataframe
</span><span class="n">dt_norm</span> <span class="o">=</span> <span class="n">dtm</span><span class="p">.</span><span class="n">stack</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">dt_norm</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'index_pos'</span><span class="p">,</span> <span class="s">'topic_id'</span><span class="p">,</span> <span class="s">'norm_topic_weight'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">compile_dataframe</span><span class="p">(</span><span class="n">docs_index</span><span class="p">,</span> <span class="n">dt_norm</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span>
</code></pre></div></div>

<div>
<style>
    .dataframe {
        font-size: 12px;
    }
    </style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index_pos</th>
      <th>topic_id</th>
      <th>norm_topic_weight</th>
      <th>topic_words</th>
      <th>doc_id</th>
      <th>year</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0.045525</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page1.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page2.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page3.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page4.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>0</td>
      <td>0.000000</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
      <td>GCB186305XX-VXX-XX-page5.txt</td>
      <td>1863</td>
      <td>GCB</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>288595</th>
      <td>11539</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page4.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288596</th>
      <td>11540</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page5.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288597</th>
      <td>11541</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page6.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288598</th>
      <td>11542</td>
      <td>24</td>
      <td>0.012192</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page7.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
    <tr>
      <th>288599</th>
      <td>11543</td>
      <td>24</td>
      <td>0.000000</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
      <td>YI18721201-V20-12-page8.txt</td>
      <td>1872</td>
      <td>YI</td>
    </tr>
  </tbody>
</table>
<p>288600 rows × 7 columns</p>
</div>

<h1 id="data-dictionary">Data dictionary:</h1>

<ul>
  <li><code class="language-plaintext highlighter-rouge">index_pos</code> : Gensim uses the order in which the docs were streamed to link back the data and the source file. <code class="language-plaintext highlighter-rouge">index_pos</code> refers to the index id for the individual doc, which I used to link the resulting model information with the document name.</li>
  <li><code class="language-plaintext highlighter-rouge">topic_id</code> : The numerical id for each topic. For this model, I used 20 topics to classify the periodical pages.</li>
  <li><code class="language-plaintext highlighter-rouge">norm_topic_weight</code> : The proportion of the tokens in the document that are part of the topic, normalized per doc.</li>
  <li><code class="language-plaintext highlighter-rouge">topic_words</code> : The top 6 words in the topic.</li>
  <li><code class="language-plaintext highlighter-rouge">doc_id</code> : The file name of the document. The filename contains metadata information about the document, such as the periodical title, date of publication, volume, issue, and page number.</li>
  <li><code class="language-plaintext highlighter-rouge">year</code> : Year the document was published (according to the filename)</li>
  <li><code class="language-plaintext highlighter-rouge">title</code> : Periodical that the page was published in.</li>
</ul>

<h2 id="normalizing-weights-to-proportion-of-total">Normalizing Weights to Proportion of Total</h2>

<p>The final method for topic weights over time is calculating a normalized or proportional weight. If I read the code correctly, this is the approach that Goldstone uses in his <a href="https://github.com/agoldst/dfrtopics/blob/43362fd4aea25caedf59f610fb02f3aaa30334ca/R/matrices.R#L2-L122">dfr topics library</a>. Rather than computing the average weight, in this approach we sum up all of the values for each topic in a given time frame, and then normalize those values by dividing by the sum of all the weights in that period. In the normalized data, the sum of all the normalized weights for each time period is 1.</p>

<p>This allows us to see the proportion of the total weight that is held by each individual topic in each period. As a topic increases in a corpus, it takes up a larger proportion of the total weight.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'year'</span><span class="p">,</span> <span class="s">'topic_id'</span><span class="p">]).</span><span class="n">agg</span><span class="p">({</span><span class="s">'norm_topic_weight'</span><span class="p">:</span> <span class="s">'sum'</span><span class="p">})</span>

<span class="c1"># This achieves a similar computation as the normalizing function above, but without converting into a matrix first.
# For each group (in this case year), we are dividing the values by the sum of the values. 
</span><span class="n">ny_df</span> <span class="o">=</span> <span class="n">y_df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">/</span> <span class="n">x</span><span class="p">.</span><span class="nb">sum</span><span class="p">()).</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">ny_df</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'year'</span><span class="p">,</span> <span class="s">'topic_id'</span><span class="p">,</span> <span class="s">'normalized_weight'</span><span class="p">]</span>
<span class="n">ny_df</span> <span class="o">=</span> <span class="n">ny_df</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">"topic_id"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ny_df</span>
</code></pre></div></div>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>topic_id</th>
      <th>normalized_weight</th>
      <th>topic_words</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1859</td>
      <td>0</td>
      <td>0.127749</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1860</td>
      <td>0</td>
      <td>0.119807</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1861</td>
      <td>0</td>
      <td>0.132227</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1862</td>
      <td>0</td>
      <td>0.109252</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1863</td>
      <td>0</td>
      <td>0.109100</td>
      <td>satan, salvation, sinner, righteousness, peace...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>420</th>
      <td>1871</td>
      <td>24</td>
      <td>0.001333</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
    </tr>
    <tr>
      <th>421</th>
      <td>1872</td>
      <td>24</td>
      <td>0.001614</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
    </tr>
    <tr>
      <th>422</th>
      <td>1873</td>
      <td>24</td>
      <td>0.001359</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
    </tr>
    <tr>
      <th>423</th>
      <td>1874</td>
      <td>24</td>
      <td>0.002465</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
    </tr>
    <tr>
      <th>424</th>
      <td>1875</td>
      <td>24</td>
      <td>0.001354</td>
      <td>jerusalem, thess, parable, lazarus, thou_hast,...</td>
    </tr>
  </tbody>
</table>
<p>425 rows × 4 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Limit the data to our 6 topic sample
</span><span class="n">ny_df_filtered</span> <span class="o">=</span> <span class="n">ny_df</span><span class="p">[(</span><span class="n">ny_df</span><span class="p">[</span><span class="s">'topic_id'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">15</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">ny_df</span><span class="p">[</span><span class="s">'topic_id'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">20</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_pointplot</span><span class="p">(</span><span class="n">ny_df_filtered</span><span class="p">,</span> <span class="s">"normalized_weight"</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">"topic_words"</span><span class="p">,</span> 
                 <span class="n">title</span><span class="o">=</span><span class="s">"Proportion of total topic weight by topic per year."</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.FacetGrid at 0x116f21588&gt;
</code></pre></div></div>

<p><img src="/assets/img/output_23_1.png" alt="" /></p>

<p>This graph is very similar to what we see when we use Seaborn to compute the mean topic weight per year.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_pointplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s">'norm_topic_weight'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'topic_words'</span><span class="p">,</span>
                 <span class="n">title</span><span class="o">=</span><span class="s">'Central range of topic weights by topic per year.'</span>
                <span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.FacetGrid at 0x113bf4160&gt;
</code></pre></div></div>

<p><img src="/assets/img/output_25_2.png" alt="" /></p>

<p>One advantage of this method is that it is easy to aggregate by a factor other than time, such as periodical title, to see the overall distribution of topics within different subsets of the corpus.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">titles</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'topic_id'</span><span class="p">]).</span><span class="n">agg</span><span class="p">({</span><span class="s">'norm_topic_weight'</span><span class="p">:</span> <span class="s">'sum'</span><span class="p">})</span>
<span class="n">titles</span> <span class="o">=</span> <span class="n">titles</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">/</span> <span class="n">x</span><span class="p">.</span><span class="nb">sum</span><span class="p">()).</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">titles</span> <span class="o">=</span> <span class="n">titles</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'topic_id'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">titles</span><span class="p">.</span><span class="n">pivot</span><span class="p">(</span><span class="s">'title'</span><span class="p">,</span><span class="s">'topic_words'</span><span class="p">,</span> <span class="s">'norm_topic_weight'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">stacked</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">colormap</span><span class="o">=</span><span class="s">'Paired'</span><span class="p">,</span> 
      <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s">'Normalized proportions of topic weights per title.'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.75</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.legend.Legend at 0x106eb4358&gt;
</code></pre></div></div>

<p><img src="/assets/img/output_28_1.png" alt="" /></p>

<p>Another advantage of this method is that it makes it easier to accommodate the default Gensim data output (where values less than 1% are dropped). We can see this by charting the normalized weights after dropping the zero values and comparing that to a chart of the average weights after dropping the zero values.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Remove the zero values we added in when normalizing each document
</span><span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'norm_topic_weight'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p_df2</span> <span class="o">=</span> <span class="n">df2</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'year'</span><span class="p">,</span> <span class="s">'topic_id'</span><span class="p">]).</span><span class="n">agg</span><span class="p">({</span><span class="s">'norm_topic_weight'</span><span class="p">:</span> <span class="s">'sum'</span><span class="p">})</span>

<span class="c1"># Normalize each group by dividing by the sum of the group
</span><span class="n">np_df2</span> <span class="o">=</span> <span class="n">p_df2</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">/</span> <span class="n">x</span><span class="p">.</span><span class="nb">sum</span><span class="p">()).</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">np_df2</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'year'</span><span class="p">,</span> <span class="s">'topic_id'</span><span class="p">,</span> <span class="s">'normalized_weight'</span><span class="p">]</span>
<span class="n">np_df2</span> <span class="o">=</span> <span class="n">np_df2</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">"topic_id"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np_df2_filtered</span> <span class="o">=</span> <span class="n">np_df2</span><span class="p">[(</span><span class="n">np_df2</span><span class="p">[</span><span class="s">'topic_id'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">15</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">np_df2</span><span class="p">[</span><span class="s">'topic_id'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">20</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_pointplot</span><span class="p">(</span><span class="n">np_df2_filtered</span><span class="p">,</span> <span class="s">"normalized_weight"</span><span class="p">,</span> 
<span class="n">hue</span><span class="o">=</span><span class="s">"topic_words"</span><span class="p">,</span> 
<span class="n">title</span><span class="o">=</span><span class="s">"Normalized topic weights by topic per year, zero values excluded."</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.FacetGrid at 0x11434df60&gt;
</code></pre></div></div>

<p><img src="/assets/img/output_33_1.png" alt="" /></p>

<p>Whereas, if we compute the mean values on the default Gensim report, we get a very different (and skewed) picture of the topic weights per year.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_pointplot</span><span class="p">(</span><span class="n">df2</span><span class="p">,</span> <span class="s">'norm_topic_weight'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'topic_words'</span><span class="p">,</span>
                 <span class="n">title</span><span class="o">=</span><span class="s">'Central range of topic weights by topic per year, zero values excluded.'</span>
                <span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.FacetGrid at 0x115797d68&gt;
</code></pre></div></div>

<p><img src="/assets/img/output_35_1.png" alt="" /></p>

<p>This series of posts came to be as I went searching for models of how to aggregate the topic weights per year and, due in no small part because I forgot to account for the different ways Gensim and Mallet handle low topic weights, produced very different graphs depending on the aggregation method. Each method I found is useful for highlighting different aspects of the data: computing the mean tell us about the average weight for each topic in a given group; computing smoothing lines and rolling averages points out broader trends for a particular topic; computing prevalence helps us see when a topic is prominent; and the normalized or proportional weights helps us see the topics in relationship to one another.</p>

<p>If I have understood these methods correctly, then I find the proportional weight to be most useful for my particular questions and my data. I am interested in when and where different topics spike relative to other topics as a way to guide further research into the documents, a line of inquiry that the proportional weights are useful for exploring. Computing proportional or the normalized weights also helps me handle the default Gensim data more smoothly (by which I mean, with fewer opportunities for me to make mistakes).</p>

<p>A note on the visualizations: The charts in these notebooks are not my favorite in terms of design, readability, and accessibility. My apologies to anyone for whom the are illegible. I am still working out how best to create these visualizations for a range of users and am happy to provide an alternative if needed.</p>

<p>A special thanks to Amanda Regan for talking me through the code for her <a href="https://regan008.shinyapps.io/mining_my_day/">visualizations of Eleanor Roosevelt’s <em>My Day</em></a>.</p>

<hr />

<p><em>You can download and run the code locally using the <a href="https://github.com/jerielizabeth/Gospel-of-Health-Notebooks/blob/master/blogPosts/Calculating%20and%20Visualizing%20Topic%20Significance%20over%20Time%2C%20Part%204.ipynb">Jupyter Notebook version of this post</a></em></p>


  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2020 Jeri E. Wieringa.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.0/umd/popper.min.js" integrity="sha256-OH05DFHUWzr725HmuHo3pnuvUUn+TJuj8/Qz9xytFEw=" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/js/mdb.min.js"  integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" integrity="sha256-V8SV2MO1FUb63Bwht5Wx9x6PVHNa02gv8BgH/uH3ung=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js" integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc=" crossorigin="anonymous"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>





<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>



</html>
